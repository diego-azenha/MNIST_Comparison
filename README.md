## Resultados

### MNIST Padrao

O primeiro conjunto de experimentos foi realizado com a base MNIST original, composta por imagens de d√≠gitos manuscritos (28√ó28 pixels, em tons de cinza), bem centralizadas e com pouco ru√≠do. Os modelos treinados foram uma Rede Neural Convolucional (CNN), uma Rede Neural Feedforward (MLP) e uma Random Forest (RF). Todos os modelos foram avaliados com base em m√©tricas cl√°ssicas de classifica√ß√£o multiclasse.

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | 0.991    | 0.9909   | **0.0268** ‚úÖ |
| **MLP**          | 0.974    | 0.9733   | 0.0900 ‚ö†Ô∏è |
| **Random Forest**| 0.970    | 0.9702   | **0.2466** üî¥ |


A CNN apresentou desempenho superior em todas as m√©tricas, com maior precis√£o e menor entropia (log loss). O MLP tamb√©m obteve resultados robustos, embora com pequenas quedas em classes mais visuais como 2, 3 e 8. A Random Forest, apesar de competitiva em acur√°cia, mostrou-se menos calibrada ‚Äî evidenciado por um log loss mais alto.

#### An√°lise Qualitativa

- CNN: Erros residuais concentrados em d√≠gitos visualmente amb√≠guos (como 5 vs 3 ou 9 vs 4), mas com excelente generaliza√ß√£o.

- MLP: Desempenho s√≥lido, mas mais sens√≠vel a varia√ß√µes sutis de tra√ßo.

- RF: Forte capacidade de classifica√ß√£o geral, por√©m mais suscet√≠vel a confus√µes entre d√≠gitos parecidos, especialmente em regi√µes lim√≠trofes do espa√ßo de decis√£o.

#### Gr√°ficos gerados:

Matrizes de confus√£o e curvas ROC One-vs-All para cada modelo (dispon√≠veis na pasta /results).


### MNIST-C

Para avaliar a robustez dos modelos em condi√ß√µes adversas mais pr√≥ximas de aplica√ß√µes reais, testamos CNN, MLP e Random Forest sobre a base MNIST-C, que introduz distor√ß√µes visuais sistem√°ticas aos d√≠gitos manuscritos. Utilizamos as corrup√ß√µes shot_noise e motion_blur, ambas com severidade 5, representando cen√°rios dif√≠ceis, por√©m leg√≠veis.

As m√©tricas consideradas foram acur√°cia, macro F1-score e log loss (entropia cruzada), esta √∫ltima sendo crucial para medir calibra√ß√£o de confian√ßa dos modelos.

#### Corrupcao: brightness (severidade 5)

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | 0.982    | 0.9816   | **0.0543** ‚úÖ |
| **MLP**          | 0.927    | 0.9251   | 0.2637 ‚ö†Ô∏è |
| **Random Forest**| 0.971    | 0.9704   | **0.3017** üî¥ |

#### Corrupcao: shot-noise (severidade 5)

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | 0.979    | 0.9776   | **0.0618** ‚úÖ |
| **MLP**          | 0.955    | 0.9531   | 0.1606 ‚ö†Ô∏è |
| **Random Forest**| 0.955    | 0.9534   | **0.4516** üî¥ |


#### Corrupcao: motion-blur (severidade 5)

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | 0.977    | 0.9761   | **0.0658** ‚úÖ |
| **MLP**          | 0.956    | 0.9542   | 0.1388 ‚ö†Ô∏è |
| **Random Forest**| 0.964    | 0.9628   | **0.3317** üî¥ |

