## Estrutura do projeto

```
APS MPA/
‚îú‚îÄ‚îÄ ConvNN.py              # Defini√ß√£o e treinamento da rede neural convolucional (CNN)
‚îú‚îÄ‚îÄ MLP.py                 # Defini√ß√£o e treinamento da rede MLP fully-connected
‚îú‚îÄ‚îÄ RandomForest.py        # Implementa√ß√£o do classificador Random Forest usando Scikit-Learn
‚îú‚îÄ‚îÄ main.py                # Script principal para rodar os modelos e gerar m√©tricas
‚îú‚îÄ‚îÄ metrics.py             # Gera√ß√£o de gr√°ficos (ROC, matriz de confus√£o) e m√©tricas detalhadas
‚îú‚îÄ‚îÄ data_loader.py         # Fun√ß√µes de carregamento e pr√©-processamento de MNIST e MNIST-C
‚îú‚îÄ‚îÄ README.md              # Documenta√ß√£o do projeto
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias necess√°rias para executar o projeto
‚îÇ
‚îú‚îÄ‚îÄ data/                  # Dados originais do MNIST (baixados automaticamente pelo torchvision)
‚îÇ
‚îú‚îÄ‚îÄ mnist_c/               # Vers√£o corrompida do MNIST (MNIST-C), organizada por tipo de distor√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ brightness/
‚îÇ   ‚îú‚îÄ‚îÄ shot_noise/
‚îÇ   ‚îî‚îÄ‚îÄ ...                # Outras corrup√ß√µes (motion_blur, fog, etc.)
‚îÇ
‚îú‚îÄ‚îÄ modelos/               # (Opcional) Diret√≥rio para salvar pesos dos modelos treinados
‚îú‚îÄ‚îÄ results/               # Gr√°ficos, m√©tricas e arquivos gerados durante os testes
‚îî‚îÄ‚îÄ .venv/                 # Ambiente virtual Python (opcional, mas recomendado)
```

## Resultados

As m√©tricas utilizadas para avaliar os modelos foram:

- **Matriz de confus√£o**: tabela que relaciona as classes verdadeiras com as classes preditas, destacando acertos na diagonal principal e erros fora dela. Permite identificar padr√µes espec√≠ficos de confus√£o entre classes.

- **Curvas ROC (One-Versus-All)**: conjunto de curvas ROC, uma para cada classe, em que cada classe √© tratada como positiva e todas as outras como negativas. Mostra a capacidade do modelo de separar corretamente cada classe individualmente em termos de taxa de verdadeiros positivos e falsos positivos.

- **Acur√°cia**: propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de exemplos.

  \[
  \text{Acur√°cia} = \frac{\text{n√∫mero de acertos}}{\text{total de exemplos}}
  \]

- **Macro F1-score**: m√©dia harm√¥nica entre precis√£o e revoca√ß√£o, calculada separadamente para cada classe e depois agregada.

  \[
  \text{Macro F1} = \frac{1}{K} \sum_{i=1}^{K} \text{F1-score}_i
  \]

- **Log Loss** (entropia cruzada): mede a negatividade logar√≠tmica da probabilidade atribu√≠da √† classe correta.

  \[
  \text{Log Loss} = -\frac{1}{N} \sum_{i=1}^{N} \log(p_{\text{correto}}^{(i)})
  \]


### MNIST Padrao

O primeiro conjunto de experimentos foi realizado com a base MNIST original, composta por imagens de d√≠gitos manuscritos (28√ó28 pixels, em tons de cinza), bem centralizadas e com pouco ru√≠do. Os modelos treinados foram uma Rede Neural Convolucional (CNN), uma Rede Neural Feedforward (MLP) e uma Random Forest (RF). Todos os modelos foram avaliados com base em m√©tricas cl√°ssicas de classifica√ß√£o multiclasse.

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | **0.991**    | **0.9909**   | **0.0268** ‚úÖ |
| **MLP**          | 0.974    | 0.9733   | 0.0900 ‚ö†Ô∏è |
| **Random Forest**| 0.970    | 0.9702   | **0.2466** üî¥ |


A CNN apresentou desempenho superior em todas as m√©tricas, com maior precis√£o e menor entropia (log loss). O MLP tamb√©m obteve resultados robustos, embora com pequenas quedas em classes mais visuais como 2, 3 e 8. A Random Forest, apesar de competitiva em acur√°cia, mostrou-se menos calibrada ‚Äî evidenciado por um log loss mais alto.

#### An√°lise Qualitativa

- CNN: Erros residuais concentrados em d√≠gitos visualmente amb√≠guos (como 5 vs 3 ou 9 vs 4), mas com excelente generaliza√ß√£o.

- MLP: Desempenho s√≥lido, mas mais sens√≠vel a varia√ß√µes sutis de tra√ßo.

- RF: Forte capacidade de classifica√ß√£o geral, por√©m mais suscet√≠vel a confus√µes entre d√≠gitos parecidos, especialmente em regi√µes lim√≠trofes do espa√ßo de decis√£o.

#### Gr√°ficos gerados:

Matrizes de confus√£o e curvas ROC One-vs-All para cada modelo (dispon√≠veis na pasta /results).


### MNIST-C

Para avaliar a robustez dos modelos em condi√ß√µes adversas mais pr√≥ximas de aplica√ß√µes reais, testamos CNN, MLP e Random Forest sobre a base MNIST-C, que introduz distor√ß√µes visuais sistem√°ticas aos d√≠gitos manuscritos. Utilizamos as corrup√ß√µes shot_noise e motion_blur, ambas com severidade 5, representando cen√°rios dif√≠ceis, por√©m leg√≠veis.

As m√©tricas consideradas foram acur√°cia, macro F1-score e log loss (entropia cruzada), esta √∫ltima sendo crucial para medir calibra√ß√£o de confian√ßa dos modelos.

#### Corrupcao: brightness (severidade 5)

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | **0.982**   | **0.9816**   | **0.0543** ‚úÖ |
| **MLP**          | 0.927    | 0.9251   | 0.2637 ‚ö†Ô∏è |
| **Random Forest**| 0.971    | 0.9704   | **0.3017** üî¥ |

#### Corrupcao: shot-noise (severidade 5)

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | **0.979**    | **0.9776**   | **0.0618** ‚úÖ |
| **MLP**          | 0.955    | 0.9531   | 0.1606 ‚ö†Ô∏è |
| **Random Forest**| 0.955    | 0.9534   | **0.4516** üî¥ |


#### Corrupcao: motion-blur (severidade 5)

| Modelo           | Acur√°cia | Macro F1 | Log Loss |
|------------------|----------|----------|----------|
| **CNN**          | **0.977**    | **0.9761**   | **0.0658** ‚úÖ |
| **MLP**          | 0.956    | 0.9542   | 0.1388 ‚ö†Ô∏è |
| **Random Forest**| 0.964    | 0.9628   | **0.3317** üî¥ |

